dataset:
  train_fname: 'n_alternates_1+_latin_stratified_split_x_train.csv'
  val_fname: 'n_alternates_1+_latin_stratified_split_x_val.csv'
  max_chars: 32
tokenizer:
  #  someone can use unigram_tokenizer as well
  name: trigram_tokenizer
  maxlen: 32
  # remove num_words if you want to use all the generated tokens
  num_words: 50000
train_sampler:
  name: sampler
  batch_size: 2048
  n_positives: 1
  n_negatives: 3
  neg_samples_size: 30
  shuffle: true
val_sampler:
  name: sampler
  batch_size: 2048
  n_positives: 1
  n_negatives: 3
  neg_samples_size: 30
  shuffle: true
model:
  name: 'siamese_net'
  encoder: 'lstm1'
criterion:
  name: 'binary_crossentropy'
optimizer:
  name: 'adam'
  lr: 0.001
metrics:
  accuracy: 'primary'
  AUC: 'primary'
training:
  num_epochs: 50
  num_workers: 8
  multi_process: false
