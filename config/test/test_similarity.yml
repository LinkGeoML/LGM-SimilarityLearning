dataset:
  fname: 'n_alternates_1+_latin_stratified_split_x_test.csv'
  tokenizer_fname: 'unigram_tokenizer_nw_20000_ml_32.json'
  use_external: false
model:
  name: 'siamese_net'
  encoder: 'lstm1'
  num_classes: 2
criterion:
  name: 'cross_entropy_loss'
optimizer:
  name: 'adam'
  lr: 0.001
test_sampler:
  batch_size: 1024
  shuffle: true
metrics:
  accuracy: 'primary'
  AUC: 'primary'
